{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "locationList = ['ufop.br']#,'usp.br,unicamp.br','unesp.br','ufsc.br','pucrs.br','df.ufscar.br','ufop.br','aluno.unb.br','dac.unicamp.br','ifsc.edu.br']\n",
    "\n",
    "df_ok = pd.read_csv('radiusLoginOk.csv')\n",
    "df_in = pd.read_csv('radiusLoginIncorrect.csv')\n",
    "\n",
    "t = 5\n",
    "p = 5\n",
    "q = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lucas\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\Lucas\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in locationList:\n",
    "    df1 = df_ok[df_ok['Domain'] == i]\n",
    "    df2 = df_in[df_in['Domain'] == i]\n",
    "    \n",
    "    df1['Date'] = pd.to_datetime(df1['Date'])\n",
    "    df1.set_index(['Date'])\n",
    "    \n",
    "    df2['Date'] = pd.to_datetime(df2['Date'])\n",
    "    df2.set_index(['Date'])\n",
    "    \n",
    "    df1 = df1.groupby([pd.Grouper(key='Date',freq='{}Min'.format(t))]).agg({'ID':'count'})\n",
    "    df1 = df1.rename(columns={'ID' : 'count'})\n",
    "    \n",
    "    df2 = df2.groupby([pd.Grouper(key='Date',freq='{}Min'.format(t))]).agg({'ID':'count'})\n",
    "    df2 = df2.rename(columns={'ID' : 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClass(df1,df2):\n",
    "    if df1 >= df2:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12431\n",
      "206146\n"
     ]
    }
   ],
   "source": [
    "print(len(df1))\n",
    "print(len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[193715:]\n",
    "df1 = df1.reset_index().values\n",
    "df2 = df2.reset_index().values\n",
    "\n",
    "newdf = []\n",
    "for i in range(0,len(df1)):\n",
    "    line = []\n",
    "    for j in range(0,len(df1[i])):\n",
    "        if j == 0:\n",
    "            line.append(df1[i,j])\n",
    "        elif j == 1:\n",
    "            line.append(getClass(df1[i,j],df2[i,j]))\n",
    "    newdf.append(line)\n",
    "    \n",
    "df = pd.DataFrame(newdf,columns=['Date','Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1414\n",
      "11017\n"
     ]
    }
   ],
   "source": [
    "print(len(df[df['Count'] == 1]))\n",
    "print(len(df[df['Count'] == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range( 1, q + 1):\n",
    "    df['Count-{}'.format(i)] = df['Count'].shift(i * 7 * 24 * 60 // t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763\n",
      "2672\n"
     ]
    }
   ],
   "source": [
    "df = df[q * (5 * 13 * 60 // t + 5):]\n",
    "dfaux = df\n",
    "dfaux = dfaux.set_index(['Date'])\n",
    "dfaux = dfaux[dfaux.index.weekday < 5]\n",
    "dfaux = dfaux.between_time('8:00','20:00')\n",
    "print(len(dfaux[dfaux['Count'] == 1]))\n",
    "print(len(dfaux[dfaux['Count'] == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = list()\n",
    "Y1 = list()\n",
    "\n",
    "for i in range(len(dfaux) - p - 1):\n",
    "    X = list()\n",
    "    for j in range(1, q + 1):\n",
    "        X.append(dfaux['Count-{}'.format(j)][i + p + 1])\n",
    "    X1.append(X + list(dfaux['Count'][i:(i + p)]))\n",
    "    Y1.append(dfaux['Count'][i + p + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X1,Y1, test_size= 0.4, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(60), max_iter=500, alpha=0.0001,\n",
    "                     solver='adam', verbose=10,  random_state=21,tol=0.000000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.64154743\n",
      "Iteration 2, loss = 0.60447337\n",
      "Iteration 3, loss = 0.57266133\n",
      "Iteration 4, loss = 0.54597932\n",
      "Iteration 5, loss = 0.52243037\n",
      "Iteration 6, loss = 0.50218873\n",
      "Iteration 7, loss = 0.48440371\n",
      "Iteration 8, loss = 0.46939621\n",
      "Iteration 9, loss = 0.45700027\n",
      "Iteration 10, loss = 0.44534710\n",
      "Iteration 11, loss = 0.43584785\n",
      "Iteration 12, loss = 0.42781746\n",
      "Iteration 13, loss = 0.42135971\n",
      "Iteration 14, loss = 0.41549426\n",
      "Iteration 15, loss = 0.41106944\n",
      "Iteration 16, loss = 0.40734304\n",
      "Iteration 17, loss = 0.40444434\n",
      "Iteration 18, loss = 0.40205047\n",
      "Iteration 19, loss = 0.39968944\n",
      "Iteration 20, loss = 0.39822561\n",
      "Iteration 21, loss = 0.39683130\n",
      "Iteration 22, loss = 0.39568506\n",
      "Iteration 23, loss = 0.39496792\n",
      "Iteration 24, loss = 0.39381128\n",
      "Iteration 25, loss = 0.39330362\n",
      "Iteration 26, loss = 0.39260616\n",
      "Iteration 27, loss = 0.39242643\n",
      "Iteration 28, loss = 0.39182015\n",
      "Iteration 29, loss = 0.39143283\n",
      "Iteration 30, loss = 0.39092488\n",
      "Iteration 31, loss = 0.39084073\n",
      "Iteration 32, loss = 0.39040842\n",
      "Iteration 33, loss = 0.39008807\n",
      "Iteration 34, loss = 0.38984913\n",
      "Iteration 35, loss = 0.38955842\n",
      "Iteration 36, loss = 0.38938999\n",
      "Iteration 37, loss = 0.38918496\n",
      "Iteration 38, loss = 0.38897188\n",
      "Iteration 39, loss = 0.38895979\n",
      "Iteration 40, loss = 0.38842777\n",
      "Iteration 41, loss = 0.38838422\n",
      "Iteration 42, loss = 0.38803948\n",
      "Iteration 43, loss = 0.38792327\n",
      "Iteration 44, loss = 0.38770565\n",
      "Iteration 45, loss = 0.38747131\n",
      "Iteration 46, loss = 0.38725484\n",
      "Iteration 47, loss = 0.38717439\n",
      "Iteration 48, loss = 0.38696654\n",
      "Iteration 49, loss = 0.38665881\n",
      "Iteration 50, loss = 0.38647398\n",
      "Iteration 51, loss = 0.38634958\n",
      "Iteration 52, loss = 0.38608057\n",
      "Iteration 53, loss = 0.38586123\n",
      "Iteration 54, loss = 0.38571366\n",
      "Iteration 55, loss = 0.38571414\n",
      "Iteration 56, loss = 0.38530203\n",
      "Iteration 57, loss = 0.38515564\n",
      "Iteration 58, loss = 0.38507625\n",
      "Iteration 59, loss = 0.38480092\n",
      "Iteration 60, loss = 0.38463466\n",
      "Iteration 61, loss = 0.38448299\n",
      "Iteration 62, loss = 0.38441050\n",
      "Iteration 63, loss = 0.38421021\n",
      "Iteration 64, loss = 0.38400213\n",
      "Iteration 65, loss = 0.38368474\n",
      "Iteration 66, loss = 0.38346835\n",
      "Iteration 67, loss = 0.38337036\n",
      "Iteration 68, loss = 0.38341933\n",
      "Iteration 69, loss = 0.38309372\n",
      "Iteration 70, loss = 0.38288239\n",
      "Iteration 71, loss = 0.38287409\n",
      "Iteration 72, loss = 0.38262377\n",
      "Iteration 73, loss = 0.38260470\n",
      "Iteration 74, loss = 0.38243720\n",
      "Iteration 75, loss = 0.38219148\n",
      "Iteration 76, loss = 0.38226865\n",
      "Iteration 77, loss = 0.38218072\n",
      "Iteration 78, loss = 0.38190426\n",
      "Iteration 79, loss = 0.38166548\n",
      "Iteration 80, loss = 0.38157477\n",
      "Iteration 81, loss = 0.38152459\n",
      "Iteration 82, loss = 0.38135736\n",
      "Iteration 83, loss = 0.38137632\n",
      "Iteration 84, loss = 0.38122239\n",
      "Iteration 85, loss = 0.38114795\n",
      "Iteration 86, loss = 0.38091728\n",
      "Iteration 87, loss = 0.38086666\n",
      "Iteration 88, loss = 0.38061339\n",
      "Iteration 89, loss = 0.38072371\n",
      "Iteration 90, loss = 0.38039742\n",
      "Iteration 91, loss = 0.38047275\n",
      "Iteration 92, loss = 0.38028947\n",
      "Iteration 93, loss = 0.38056059\n",
      "Iteration 94, loss = 0.38017527\n",
      "Iteration 95, loss = 0.38029364\n",
      "Iteration 96, loss = 0.38016464\n",
      "Iteration 97, loss = 0.37985170\n",
      "Iteration 98, loss = 0.37996102\n",
      "Iteration 99, loss = 0.37973183\n",
      "Iteration 100, loss = 0.37952876\n",
      "Iteration 101, loss = 0.37937161\n",
      "Iteration 102, loss = 0.37940390\n",
      "Iteration 103, loss = 0.37922247\n",
      "Iteration 104, loss = 0.37921737\n",
      "Iteration 105, loss = 0.37914101\n",
      "Iteration 106, loss = 0.37898362\n",
      "Iteration 107, loss = 0.37900943\n",
      "Iteration 108, loss = 0.37885023\n",
      "Iteration 109, loss = 0.37861659\n",
      "Iteration 110, loss = 0.37864158\n",
      "Iteration 111, loss = 0.37862184\n",
      "Iteration 112, loss = 0.37857739\n",
      "Iteration 113, loss = 0.37842271\n",
      "Iteration 114, loss = 0.37819373\n",
      "Iteration 115, loss = 0.37816794\n",
      "Iteration 116, loss = 0.37804762\n",
      "Iteration 117, loss = 0.37794504\n",
      "Iteration 118, loss = 0.37798386\n",
      "Iteration 119, loss = 0.37808892\n",
      "Iteration 120, loss = 0.37767853\n",
      "Iteration 121, loss = 0.37791300\n",
      "Iteration 122, loss = 0.37789615\n",
      "Iteration 123, loss = 0.37765329\n",
      "Iteration 124, loss = 0.37743724\n",
      "Iteration 125, loss = 0.37732116\n",
      "Iteration 126, loss = 0.37734948\n",
      "Iteration 127, loss = 0.37712099\n",
      "Iteration 128, loss = 0.37714519\n",
      "Iteration 129, loss = 0.37706267\n",
      "Iteration 130, loss = 0.37682645\n",
      "Iteration 131, loss = 0.37687979\n",
      "Iteration 132, loss = 0.37680058\n",
      "Iteration 133, loss = 0.37666611\n",
      "Iteration 134, loss = 0.37675961\n",
      "Iteration 135, loss = 0.37657510\n",
      "Iteration 136, loss = 0.37645824\n",
      "Iteration 137, loss = 0.37653659\n",
      "Iteration 138, loss = 0.37632611\n",
      "Iteration 139, loss = 0.37608839\n",
      "Iteration 140, loss = 0.37610884\n",
      "Iteration 141, loss = 0.37608723\n",
      "Iteration 142, loss = 0.37603236\n",
      "Iteration 143, loss = 0.37573942\n",
      "Iteration 144, loss = 0.37573756\n",
      "Iteration 145, loss = 0.37573328\n",
      "Iteration 146, loss = 0.37572047\n",
      "Iteration 147, loss = 0.37548693\n",
      "Iteration 148, loss = 0.37581856\n",
      "Iteration 149, loss = 0.37551176\n",
      "Iteration 150, loss = 0.37533792\n",
      "Iteration 151, loss = 0.37525192\n",
      "Iteration 152, loss = 0.37521317\n",
      "Iteration 153, loss = 0.37579299\n",
      "Iteration 154, loss = 0.37534813\n",
      "Iteration 155, loss = 0.37531178\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8352769679300291"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1015,   74],\n",
       "       [ 152,  131]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm, center=True)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for i in y_pred:\n",
    "    if i == 1:\n",
    "        c += 1\n",
    "        \n",
    "print(c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
